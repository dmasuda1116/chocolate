# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GGa1PLboxKxfOMtFqo9tW5Y5R_ZGzHPd
"""

from google.colab import drive
drive.mount('/content/drive')

import os

base_dir = '/content/drive/MyDrive/'
os.listdir(base_dir)

"""
This script is for converting csv and modifying data to quantify features and to interpolate missing values.
"""
# coding: utf-8
import pandas as pd
import numpy as  np
import seaborn as sns
import matplotlib.pyplot as plt
import argparse
print('         .       ')
print('         .       ')
print('         .       ')
print('         .       ')
print('         .       ')
print('         .       ')

# データをpd.DataFrame形式で読み込む
parser = argparse.ArgumentParser('Example program')
parser.add_argument('-f','--file')
f_args = parser.parse_args()
#file_to_open = f_args.file
file_to_open = "/content/drive/MyDrive/meiji/meiji_matrix.csv"
print(file_to_open)
if not file_to_open:
    df = pd.read_csv("new2.csv", encoding='Shift-JIS')#header=None, ヘッダの使用可否
else:
    df = pd.read_csv(file_to_open, encoding='Shift-JIS')
#print(df['Sex'])
#df.iloc[0].to_list() 行をリストとして抽出
#df['特徴数'].to_list()　列をリストとして抽出


#df = org_file(columns=columns_name)
print('=============================================================')
print('dataframe loaded')
print('=============================================================')
#org_file.columns=org_file.index[0]
#print(org_file.columns)
#org_file.drop(index=0))

#showing the contents of dataframe
contents_d=df.head(8)
print('contents of dataframe')
print('-------------------------------------------------------------')
print(contents_d)
print('=============================================================')
# 各特徴量の欠損値をカウント
sum_d=df.isnull().sum()
print('=============================================================')
print('The number of the missing values')
print('-------------------------------------------------------------')
print(sum_d)
print('=============================================================')
#欠損値に対する処理
"""
# 欠損値を含む行を削除
df.dropna()
# 特徴項目Xに欠損があるサンプルのみ削除する
df.dropna(subset=['特徴項目X'])
# 欠損していない値がn個以上あるサンプルのみを残して削除
df.dropna(thresh=n)
# 補完
df.fillna(P)
====Pに入るオプション====
df.mean()：その特徴数の平均値
実数：任意
# 線形補完
ip = df.interpolate(method='linear')
ip　　たぶん使うことない
df = pd.concat([df_data, df_target], axis=1)      項目の追加
=======================
"""


#数値でない特徴量の定量化
"""
#物理的、または、性質的に順序を持つ特徴量（例：服のサイズ、暦の名前）
# マッピングの実行
#辞書の生成例
size_mapping = {'A':1, 'B':2, 'C':3, 'D':4}
df['特徴項目'] = df['特徴項目'].map(size_mapping)
df
#物理的、または、性質的に順序を持たない特徴量（例：服のサイズ、暦の名前）
# pandasでone-hotエンコーディング。ダミー変数を作成
pd.get_dummies(df['特徴項目'])
"""
#dataframeの保存
#df.to_csv("任意.csv")

df2=pd.concat([df["名称"], df['たんぱく質'], df['エネルギー'], df['内容量'], df['炭水化物'], df['脂質'], df['食塩相当量']], axis=1)

df3 = df2.replace(["kcal","g"],"", regex=True)

df4=pd.concat([df3['たんぱく質'], df3['エネルギー'], df3['炭水化物'], df3['脂質'], df3['食塩相当量']], axis=1)

df4

X = df4.values

#写経【２】
# データの標準化
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X)
X_std = scaler.fit_transform(X)

#写経【３】
# 主成分分析の実行
#PCAのクラスを読み込む
from sklearn.decomposition import PCA

#PCAのインスタンスを生成
pca = PCA(n_components=4)
X_pca = pca.fit_transform(X_std)

#写経【４】
# k-means法を実行
from sklearn.cluster import KMeans
km = KMeans(n_clusters=3,
            init='random',
            n_init=10,
            max_iter=300,
            tol=1e-4,
            random_state=0,
           )

# クラスラベルを予測
y_km = km.fit_predict(X_pca[:, 0:2])

# Commented out IPython magic to ensure Python compatibility.
#写経【５】
# クラスタリングの結果を出力
# ライブラリをインポート
import matplotlib.pyplot as plt
# %matplotlib inline

# クラスタリングの結果をプロットする関数
# (クラスタの数, 学習器, 学習データ)
def kmeans_plot(n_clusters, km, X):
    # クラスタの予測値を算出
    y_km = km.fit_predict(X)
    
    # クラスタごとに散布図をプロット
    # 5クラスまでプロットできる
    for i, color, marker in zip(range(n_clusters), 'rgbcm', '>o+xv'):
        plt.scatter(X[y_km==i, 0],            # 横軸の値
                    X[y_km==i, 1],            # 縦軸の値
                    color=color,              # プロットの色
                    marker=marker,            # プロットの形
                    label='cluster ' + str(i) # ラベル
                   )
    
    # クラスタの中心をプロット
    plt.scatter(km.cluster_centers_[:, 0],    # 横軸の値
                km.cluster_centers_[:, 1],    # 縦軸の値
                color='y',                    # プロットの色
                marker='*',                   # プロットの形
                label='centroids',            # ラベル
                s=300,                        # プロットのサイズを大きくして見やすくする
               )
    
    plt.legend()
    plt.grid()
    plt.show()

#写経【６】
# プロットを実行
kmeans_plot(3, km, X_pca[:, 0:2])

#写経【７】
# y_kmを確認
y_km

print((pd.concat([df2["名称"]], axis=1).values))

